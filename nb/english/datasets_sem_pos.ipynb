{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# BERT base-uncased, soma dos score do par.\n",
    "\n",
    "- Usando 4 datasets do artigo DIVE.\n",
    "\n",
    "- Os primeiros gráficos mostram o balanceamento de cada dataset.\n",
    "  - % dos pares True para cada tamanho de subtoken\n",
    "\n",
    "  - Quantidade total de pares para cada tamanho de subtoken\n",
    "\n",
    "- O último gŕafico compara o BERT com os dados do artigo. Ainda forcei os resultados: Cada dataset tem os seus melhores padrões.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanceamento: 8 não está no dataframe!\n",
      "Balanceamento: 9 não está no dataframe!\n",
      "Balanceamento: 11 não está no dataframe!\n",
      "Balanceamento: 10 não está no dataframe!\n",
      "Balanceamento: 14 não está no dataframe!\n",
      "Balanceamento: 13 não está no dataframe!\n",
      "Balanceamento: 12 não está no dataframe!\n",
      "Balanceamento: 11 não está no dataframe!\n",
      "Balanceamento: 10 não está no dataframe!\n",
      "Balanceamento: 14 não está no dataframe!\n",
      "Balanceamento: 13 não está no dataframe!\n",
      "Balanceamento: 12 não está no dataframe!\n",
      "Balanceamento: 8 não está no dataframe!\n",
      "Balanceamento: 11 não está no dataframe!\n",
      "Balanceamento: 10 não está no dataframe!\n",
      "Balanceamento: 14 não está no dataframe!\n",
      "Balanceamento: 13 não está no dataframe!\n",
      "Balanceamento: 12 não está no dataframe!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nb_utils\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.clf()\n",
    "method_names = {'word2vec': 'Word2vec C', 'summation_dot_product': 'DIVE \\u0394S * C ', 'dot_product': 'DIVE C',\n",
    "                'rnd': 'random', 'summation': 'DIVE \\u0394S', 'summation_word2vec': 'DIVE \\u0394S * Word2vec C',\n",
    "                'all_subword mean_positional_rank': 'BERT Mean Pos Rank', 'all_subword min_positional_rank': 'BERT Min Pos Rank',\n",
    "                'all_subword max_pattern': 'BERT Max Pattern', 'all_subword mean_pattern': 'BERT Mean Pattern',\n",
    "                'min score_final_log(z)': 'BERT Min Pos Rank (log(z))', 'min score_final_norm': 'BERT Min Pos Rank (/ norm)',\n",
    "                'mean score_final_log(z)': 'BERT Mean Pos Rank (log(z))', 'mean score_final_norm': 'BERT Mean Pos Rank (/ norm)'}\n",
    "\n",
    "\n",
    "path_json = \"../../en-model/bert-base-uncased-test\"\n",
    "dfs = {}\n",
    "for filename in os.listdir(path_json):\n",
    "    if os.path.isfile(os.path.join(path_json, filename)) and filename.endswith(\".json\"):\n",
    "        df = nb_utils.create_dataframe(json.load(open(os.path.join(path_json, filename))))\n",
    "        dfs[filename] = df\n",
    "\n",
    "tmp = dfs[filename]\n",
    "pattern_unique_list = tmp['pattern'].unique().tolist()\n",
    "len_total_unique = tmp['len_total'].unique().tolist()\n",
    "\n",
    "df_ratios = []\n",
    "for dataset in dfs.keys():\n",
    "    df_ratio = nb_utils.balanceamento(dfs[dataset], len_size=len_total_unique, patterns=pattern_unique_list)\n",
    "    df_ratio['dataset'] = dataset\n",
    "    df_ratios.append(df_ratio)\n",
    "\n",
    "df_ratios = pd.concat(df_ratios)\n",
    "\n",
    "\n",
    "for dataset_name, df in dfs.items():\n",
    "    dfs[dataset_name] = nb_utils.logsumexp_normalization(df, len_list=len_total_unique, pattern_list=pattern_unique_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# % dos pares True por tamanho de subtoken\n",
    "g = sns.catplot(x=\"len_total\", y=\"ratio\", col=\"dataset\",\n",
    "                data=df_ratios, saturation=.5,\n",
    "                kind=\"bar\", ci=None, aspect=.6)\n",
    "(g.set_axis_labels(\"\", \"% true\")\n",
    "#   .set_xticklabels([\"Men\", \"Women\", \"Children\"])\n",
    "  .set_titles(\"{col_name} {col_var}\")\n",
    "  # .set(ylim=(0, 1))\n",
    "  .despine(left=False))\n",
    "plt.subplots_adjust(top=0.8)\n",
    "_ = g.fig.suptitle('% dos pares verdadeiros em cada dataset')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Quantidade de pares por tamanho de subtoken\n",
    "df_ratios['total'] = df_ratios['true'] + df_ratios['false']\n",
    "g = sns.catplot(x=\"len_total\", y=\"total\", col=\"dataset\",\n",
    "                data=df_ratios, saturation=.5,\n",
    "                kind=\"bar\", ci=None, aspect=.6)\n",
    "(g.set_axis_labels(\"\", \"Num pares\")\n",
    "#   .set_xticklabels([\"Men\", \"Women\", \"Children\"])\n",
    "  .set_titles(\"{col_name} {col_var}\")\n",
    "  # .set(ylim=(0, 1))\n",
    "  .despine(left=False))\n",
    "plt.subplots_adjust(top=0.8)\n",
    "_ = g.fig.suptitle('Quantidade de exemplos em cada dataset')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_pattern_train = ['{} or some other {}', '{} or any other {}', '{} and any other {}', '{} is a type of {}', '{} and some other {}', '{} which is kind of {}', '{} a special case of {}', '{} is a {}', '{} which is a example of {}', '{} and others {}', '{} which is called {}', '{} which is a class of {}', '{} or others {}', '{} , a {}', '{} including {}']\n",
    "\n",
    "# Melhores padrões para cada dataset\n",
    "best_pattern_dataset = {}\n",
    "\n",
    "for dataset_name, df in dfs.items():\n",
    "    best_pattern_dataset[dataset_name] = nb_utils.compute_dataframe_AP_by_pattern(df, key_sort=\"score_final_log(z)\", pattern_list=pattern_unique_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_dive = pd.DataFrame({'dataset': ['kotlerman2010.json', 'kotlerman2010.json', 'baroni2012.json', 'baroni2012.json', 'turney2014.json','turney2014.json', 'levy2014.json', 'levy2014.json'],\n",
    "                        'method': ['word2vec', 'summation_dot_product'] * 4,\n",
    "                        'AP': [0.395, 0.366, 0.718, 0.835, 0.521, 0.572, 0.112, 0.192]\n",
    "                        })\n",
    "df_en = []\n",
    "method_score = [\"score_final_log(z)\", \"score_final_norm\"]\n",
    "for best_pattern_num in range(1, len(best_pattern_train)+1):\n",
    "    for dataset_name, df in dfs.items():\n",
    "        # best_pattern = best_pattern_dataset[dataset_name]['padrao'].iloc[:best_pattern_num].tolist()\n",
    "        best_pattern = best_pattern_train[:best_pattern_num]\n",
    "        for score_name in method_score[:1]:\n",
    "            n_pair = df.groupby('pattern').count().iloc[0]['hiponimo']\n",
    "            hyper_num = df[df['pattern'] == pattern_unique_list[0]]['fonte'].value_counts()\n",
    "            hyper_num = hyper_num['hyper']\n",
    "            if score_name == \"score_final_log(z)\":\n",
    "                min_ap, mean_ap = nb_utils.compute_AP_by_rank(df, key_sort=score_name, best_patterns=best_pattern)\n",
    "            elif score_name == \"score_final_norm\":\n",
    "                min_ap, mean_ap = nb_utils.compute_AP_by_rank(df_240, key_sort=score_name, best_patterns=best_pattern)\n",
    "\n",
    "            df = pd.DataFrame({'n_best': [best_pattern_num],'dataset': [dataset_name], 'N': [n_pair], 'hyper_num': [hyper_num], 'method': f\"min {score_name}\", 'AP': [min_ap]})\n",
    "            df_en.append(df)\n",
    "            df = pd.DataFrame({'n_best': [best_pattern_num],'dataset': [dataset_name], 'N': [n_pair], 'hyper_num': [hyper_num], 'method': f\"mean {score_name}\", 'AP': [mean_ap]})\n",
    "            df_en.append(df)\n",
    "\n",
    "best_pattern_num = 4\n",
    "df = pd.concat(df_en)\n",
    "df = df[df['n_best'] == best_pattern_num]\n",
    "\n",
    "df = pd.concat([df, df_dive])\n",
    "df['method_format'] = df['method'].map(method_names)\n",
    "\n",
    "print(f\"Usando {best_pattern_num} melhores padrões\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# AP por método\n",
    "plt.figure(figsize=(20,8))\n",
    "ax = sns.barplot(x='dataset' ,hue=\"method_format\", y=\"AP\", ci=\"sd\",data=df)\n",
    "ax.set(xlabel=\"Método\")\n",
    "ax.set_title(f\"AP nos datasets, cada dataset usa os seus 2 melhores padrões\")\n",
    "_ = plt.xticks(rotation=75)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}