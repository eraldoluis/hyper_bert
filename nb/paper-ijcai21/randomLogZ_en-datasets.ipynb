{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IJCAI-21\n",
    "\n",
    "### Modelo BERT base-uncased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test com 10 datasets em inglês\n",
    "### Usando os 4 melhores padrões do HypeNet-train\n",
    "\n",
    "### Não usar mais SEP ou DOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando!\n",
      "kotlerman2010.json normal\n",
      "Balanceamento: [1, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30] não está no dataframe!\n",
      "levy2014.json normal\n",
      "Balanceamento: [1, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30] não está no dataframe!\n",
      "turney2014.json normal\n",
      "Balanceamento: [1, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30] não está no dataframe!\n",
      "baroni2012.json normal\n",
      "Balanceamento: [1, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30] não está no dataframe!\n",
      "EVALution.json normal\n",
      "Balanceamento: [1, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30] não está no dataframe!\n",
      "LenciBenotto.json normal\n",
      "Balanceamento: [1, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30] não está no dataframe!\n",
      "Weeds.json normal\n",
      "Balanceamento: [1, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30] não está no dataframe!\n",
      "BLESS.json normal\n",
      "Balanceamento: [1, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30] não está no dataframe!\n",
      "wordnet_test.json normal\n",
      "Balanceamento: [1, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30] não está no dataframe!\n",
      "HypeNet_test.json normal\n",
      "Balanceamento: [1, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30] não está no dataframe!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-9e151676d447>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     47\u001B[0m     \u001B[0mtype_dataset\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdataset_name\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     48\u001B[0m     \u001B[0;31m# dfs[dataset_name] = nb_utils.logsumexp_normalization(df, len_list=len_total_unique, pattern_list=pattern_unique[type_dataset])\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 49\u001B[0;31m     \u001B[0mdfs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mdataset_name\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnb_utils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlogsumexp_random_logZ\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlen_list\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlen_total_unique\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpattern_list\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpattern_unique\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtype_dataset\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdf_random\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdf_random\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfill_number\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdataset_lenMax\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mdataset_name\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     50\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documentos/hyper_bert/nb_utils.py\u001B[0m in \u001B[0;36mlogsumexp_random_logZ\u001B[0;34m(df_data, len_list, pattern_list, df_random, fill_number)\u001B[0m\n\u001B[1;32m    156\u001B[0m             \u001B[0mvalues\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpattern\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mp\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m&\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlen_total\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0msize\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    157\u001B[0m             \u001B[0mvalues\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvalues\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'bert_soma_total'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 158\u001B[0;31m             \u001B[0mvalues_random\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdf_r\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf_r\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpattern\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mp\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m&\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mdf_r\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlen_total\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0msize\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    159\u001B[0m             \u001B[0mvalues_random\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvalues_random\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'bert_soma_total'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    160\u001B[0m             \u001B[0mrandom\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshuffle\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalues_random\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/hyper_bert/lib/python3.7/site-packages/pandas/core/ops/common.py\u001B[0m in \u001B[0;36mnew_method\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m     63\u001B[0m         \u001B[0mother\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mitem_from_zerodim\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mother\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 65\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mmethod\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mother\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     66\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     67\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mnew_method\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/hyper_bert/lib/python3.7/site-packages/pandas/core/ops/__init__.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m    368\u001B[0m         \u001B[0mrvalues\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mextract_array\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mother\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mextract_numpy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    369\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 370\u001B[0;31m         \u001B[0mres_values\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcomparison_op\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlvalues\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrvalues\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mop\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    371\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    372\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_construct_result\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mres_values\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mres_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/hyper_bert/lib/python3.7/site-packages/pandas/core/ops/array_ops.py\u001B[0m in \u001B[0;36mcomparison_op\u001B[0;34m(left, right, op)\u001B[0m\n\u001B[1;32m    237\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    238\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mis_object_dtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlvalues\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 239\u001B[0;31m         \u001B[0mres_values\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcomp_method_OBJECT_ARRAY\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mop\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlvalues\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrvalues\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    240\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    241\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/hyper_bert/lib/python3.7/site-packages/pandas/core/ops/array_ops.py\u001B[0m in \u001B[0;36mcomp_method_OBJECT_ARRAY\u001B[0;34m(op, x, y)\u001B[0m\n\u001B[1;32m     53\u001B[0m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlibops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvec_compare\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mravel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mravel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mop\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     54\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 55\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlibops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mscalar_compare\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mravel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mop\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     56\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "sys.path.append(\"/home/gabrielescobar/hyper_bert\")\n",
    "import nb_utils\n",
    "print(\"Iniciando!\")\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.clf()\n",
    "\n",
    "path_json_normal = \"../../en-model/bert-base-uncased_bert_score_normal_2020-11-12_15:13:01\"\n",
    "# path_json_dot = \"../../en-model/bert-base-uncased_bert_score_dot_comb_2020-11-12_14:48:06\"\n",
    "# path_json_sep = \"../../en-model/bert-base-uncased_bert_score_sep_comb_2020-11-12_14:48:36\"\n",
    "\n",
    "#local random\n",
    "path_file_random = \"../../en-model/bert-base-uncased_bert_score_2021-01-26_20:58:01/ENrandom.json\"\n",
    "df_random = nb_utils.create_dataframe(json.load(open(path_file_random)), separator=\"\\t\")\n",
    "\n",
    "dfs = {}\n",
    "pattern_unique = {}\n",
    "dataset_lenMax = {}\n",
    "filename = \"\"\n",
    "p_filter = nb_utils.best_pattern_HypeNet_train_logz[0]\n",
    "for filename in os.listdir(path_json_normal):\n",
    "    if os.path.isfile(os.path.join(path_json_normal, filename)) and filename.endswith(\".json\"):\n",
    "        df = nb_utils.create_dataframe(json.load(open(os.path.join(path_json_normal, filename))), combination=False, separator=\"\\t\")\n",
    "        df['tipo'] = 'normal'\n",
    "        dfs[filename + \" normal\"] = df\n",
    "        dataset_lenMax[filename + \" normal\"] = df[df.pattern == p_filter]['len_total'].value_counts().max()\n",
    "pattern_unique['normal'] = df['pattern'].unique().tolist()\n",
    "\n",
    "len_total_unique = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30]\n",
    "\n",
    "df_ratios = []\n",
    "for dataset_name in dfs.keys():\n",
    "    print(dataset_name)\n",
    "    dname, type_dataset = dataset_name.split()\n",
    "    df_ratio = nb_utils.balanceamento(dfs[dataset_name], len_size=len_total_unique, patterns=pattern_unique[type_dataset])\n",
    "    df_ratio['dataset'] = dname\n",
    "    df_ratio['tipo'] = type_dataset\n",
    "    df_ratios.append(df_ratio)\n",
    "df_ratios = pd.concat(df_ratios, ignore_index=True)\n",
    "\n",
    "for dataset_name, df in dfs.items():\n",
    "    type_dataset = dataset_name.split()[-1]\n",
    "    # dfs[dataset_name] = nb_utils.logsumexp_normalization(df, len_list=len_total_unique, pattern_list=pattern_unique[type_dataset])\n",
    "    dfs[dataset_name] = nb_utils.logsumexp_random_logZ(df, len_list=len_total_unique, pattern_list=pattern_unique[type_dataset], df_random=df_random, fill_number=dataset_lenMax[dataset_name])\n",
    "\n",
    "\n",
    "df_ratios['dataset_format'] = df_ratios['dataset'].map(nb_utils.get_dataset_names())\n",
    "df_ratios['dataset_tipo'] = df_ratios['dataset_format'] + \" \" + df_ratios['tipo']\n",
    "df_ratios['ratio_percent'] = df_ratios['ratio'] * 100\n",
    "df_plot_lensubtoken = df_ratios[df_ratios['tipo'] == 'normal']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test BERT - Log(Z) em 10 datasets inglês\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráficos descritivos dos datasets de test\n",
    " - % pares verdadeiros para cada tamanho de sub-token\n",
    " - Quantidade de pares por tamanho de sub-token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# % dos pares True por tamanho de subtoken\n",
    "plt.figure(figsize=(20,8))\n",
    "g = sns.catplot(x=\"len_total\", y=\"ratio_percent\", col=\"dataset_format\", col_wrap=5,\n",
    "                data=df_plot_lensubtoken, saturation=.5,\n",
    "                kind=\"bar\", ci=None, aspect=.9, sharey=False)\n",
    "(g.set_axis_labels(\"\", \"% true pairs\")\n",
    "#   .set_xticklabels([\"Men\", \"Women\", \"Children\"])\n",
    "  .set_titles(\"{col_name}\")\n",
    "  .despine(left=False))\n",
    "plt.subplots_adjust(top=0.9, hspace=0.3)\n",
    "_ = g.fig.suptitle('% dos pares verdadeiros em cada dataset para cada tamanho de sub-token')\n",
    "# plt.savefig('num_true_por_subtoken.png', dpi=300)\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "# Quantidade de pares por tamanho de subtoken\n",
    "df_ratios['total'] = df_ratios['true'] + df_ratios['false']\n",
    "df_plot_lensubtoken = df_ratios[df_ratios['tipo'] == 'normal']\n",
    "\n",
    "\n",
    "g = sns.catplot(x=\"len_total\", y=\"total\", col=\"dataset_format\", col_wrap=5,\n",
    "                data=df_plot_lensubtoken, saturation=.5,\n",
    "                kind=\"bar\", ci=None, aspect=.9, sharey=False)\n",
    "(g.set_axis_labels(\"\", \"Number of pairs\")\n",
    "#   .set_xticklabels([\"Men\", \"Women\", \"Children\"])\n",
    "  .set_titles(\"{col_name}\")\n",
    "  # .set(ylim=(0, 1))\n",
    "  .despine(left=False))\n",
    "plt.subplots_adjust(top=0.9, hspace=0.3)\n",
    "_ = g.fig.suptitle('Quantidade de exemplos em cada dataset para cada tamanho de sub-token')\n",
    "# plt.savefig('num_pair_por_subtoken.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_en = []\n",
    "dfs2 = []\n",
    "best_pattern_train = nb_utils.best_pattern_HypeNet_train_logz\n",
    "best_pattern_num_train = 1\n",
    "for dataset_name in dfs.keys():\n",
    "    dname, type_dataset = dataset_name.split()\n",
    "    if type_dataset == 'normal':\n",
    "        df_temp= nb_utils.compute_min_mean_ap_normal(dfs[dataset_name],\n",
    "            pattern_list=best_pattern_train, dataset_name=dname, best_pattern_num=best_pattern_num_train)\n",
    "        df_temp['tipo'] = 'normal'\n",
    "        dfs2.append(df_temp)\n",
    "        df_temp = nb_utils.compute_ap_bert_soma(dfs[dataset_name], pattern_list=best_pattern_train, dataset_name=dname,\n",
    "                                                best_pattern_num=best_pattern_num_train, tipo=type_dataset)\n",
    "        df_temp['tipo'] = \"normal\"\n",
    "        dfs2.append(df_temp)\n",
    "    else:\n",
    "        raise KeyError\n",
    "\n",
    "df_en = pd.concat(dfs2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n",
    "### AP para cada método (BERT, DIVE e Word2vec)\n",
    "\n",
    "#### Usando BERT - Log(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_dive = nb_utils.get_df_dive()\n",
    "df_dive['method_format_tipo'] = df_dive['method'].map(nb_utils.method_names)\n",
    "# AP por método\n",
    "df_en['method_format_tipo'] = df_en['method_format'] + \" + \" + df_en['tipo']\n",
    "df_en = pd.concat([df_en, df_dive])\n",
    "plt.figure(figsize=(20,8))\n",
    "ax = sns.barplot(x='dataset' ,hue=\"method_format_tipo\", y=\"AP\", ci=\"sd\",data=df_en)\n",
    "ax.set(xlabel=\"Dataset\")\n",
    "ax.set_title(f\"AP nos datasets, cada dataset usa combinações geradas usando os {best_pattern_num_train} melhores\"\n",
    "             f\" padrões do DEV\")\n",
    "ax.legend(bbox_to_anchor=(1, 1))\n",
    "legend = ax.get_legend()\n",
    "_ = plt.xticks(rotation=75)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,8)) # this creates a figure 8 inch wide, 4 inch high\n",
    "g = sns.catplot(x=\"method_format_tipo\", y=\"AP\", col=\"dataset\", col_wrap=5,\n",
    "                data=df_en, saturation=.5,\n",
    "                kind=\"bar\", ci=\"sd\", aspect=.9, legend='full')\n",
    "(g.set_axis_labels(\"\", \"AP\")\n",
    "    .set_xticklabels(rotation=40, ha=\"right\")\n",
    "    .set_titles(\"{col_name}\"))\n",
    "plt.subplots_adjust(top=0.9, hspace=0.3)\n",
    "_ = g.fig.suptitle('Mesmo gráfico de cima')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dados dos gráficos acima. Apenas para visualizar mesmo!\n",
    " - Quantidade de pares e balanceamento em cada dataset\n",
    " - AP arredondando 4 casas decimais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# print contagem\n",
    "df_print = df_ratios.groupby(['dataset', 'tipo']).sum()[['true', 'false', 'total']]\n",
    "df_print['ratio'] = df_print['true'] / df_print['total']\n",
    "print(df_print)\n",
    "\n",
    "# df to csv\n",
    "df_en['dataset_format'] = df_en['dataset'].map(nb_utils.get_dataset_names())\n",
    "group_list = ['dataset_format', 'tipo','method_format_tipo', 'AP', 'N', 'hyper_num']\n",
    "df_csv = df_en[group_list]\n",
    "df_csv = df_csv.sort_values(by=group_list[:2])\n",
    "df_csv['AP'] = df_csv['AP'].round(4)\n",
    "table = pd.pivot_table(df_csv, values='AP', index=\"dataset_format\", columns=['method_format_tipo'])\n",
    "print(table)\n",
    "table.to_csv(\"bert_randompairs.csv\",index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "usar Average e min normal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}